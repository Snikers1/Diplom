{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые объекты\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Этот блок содержит глобальные переменные, необходимые для работы --------- #\n",
    "\n",
    "#Далее создается элемент класса Firefox WebDriver для нашего url\n",
    "#Единый указатель ресурса (англ. Uniform Resource Locator, URL \n",
    "# — единообразный локатор (определитель местонахождения) ресурса (в нашем случае сайт Картотеки арбитражных дел)\n",
    "url = 'http://ras.arbitr.ru/'  \n",
    "path_to_user_driver = 'C:/Users/besso/Desktop/VKR/chromedriver.exe'\n",
    "path_to_anticaptcha_plugin = 'C:/Users/besso/Desktop/VKR/anticaptcha-plugin_v0.3410.zip' # Имеется в виду Ссылка на CRX или ZIP или ZPI файл плагина, который мы скачали\n",
    "anti_captcha_key = '3d8da2d26ff3ba9552e5524629cface8'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Параметры, которые должны быть забиты из приложения !\n",
    "\n",
    "date_from = ''\n",
    "date_to = ''\n",
    "doc_text_input = 'казенное учреждение'\n",
    "download_directory = 'C:\\\\Users\\\\besso\\\\Desktop\\\\VKR\\\\'\n",
    "\n",
    "#собственно сюда нужно забить необходимые параметры\n",
    "\n",
    "#C:\\Users\\besso\\Desktop\\VKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод отправки API запроса прямо в плагин\n",
    "# Например для инициализации API ключа сервиса anti-captcha.com, необходимый для работы плагина\n",
    "# Работает только на действующей HTML страничке,\n",
    "# в нашем случае на https://antcpt.com/blank.html\n",
    "# на страницах вроде about:blank запрос не пройдет\n",
    "def acp_api_send_request(driver, message_type, data={}):\n",
    "    message = {\n",
    "        # всегда указывается именно этот получатель API сообщения\n",
    "        'receiver': 'antiCaptchaPlugin',\n",
    "        # тип запроса, например setOptions\n",
    "        'type': message_type,\n",
    "        # мерджим с дополнительными данными\n",
    "        **data\n",
    "    }\n",
    "    # выполняем JS код на странице\n",
    "    # а именно отправляем сообщение стандартным методом window.postMessage\n",
    "    return driver.execute_script(\"\"\"\n",
    "    return window.postMessage({});\n",
    "    \"\"\".format(json.dumps(message)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_chrome_options(path_to_anticaptcha_plugin):\n",
    "    # Инциируем объект опций для Хрома, чтобы иметь возможность подключить расширение\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # Ссылка на CRX или ZIP или ZPI файл плагина, который мы скачали ранее\n",
    "    options.add_extension(path_to_anticaptcha_plugin)\n",
    "    prefs = {\"plugins.always_open_pdf_externally\": True, \n",
    "            'download.default_directory': download_directory} #Без дополнительных прожатий кнопки \"скачать\" при открытии pdf-скачиваем его\n",
    "    options.add_experimental_option(\"prefs\",prefs)\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ф-ция для инцииализации веб-драйвера хрома опциями\n",
    "def get_browser_with_options(path_to_user_driver):\n",
    "    # Запускаем Браузер (Веб Драйвер Хрома) с указанием места скачивания самого файла драйвера\n",
    "    browser = webdriver.Chrome(path_to_user_driver, options=init_chrome_options(path_to_anticaptcha_plugin) )\n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ф-ция для получения стартовой страницы и обхода капчи на ней\n",
    "def get_initial_page(  url = url, anti_captcha_key = anti_captcha_key  ):\n",
    "    # Переходим на пустую страницу для выполнения API запроса к плагину\n",
    "    browser = get_browser_with_options(path_to_user_driver)\n",
    "    \n",
    "    browser.get(url)\n",
    "    \n",
    "    #здесь делаем закрытие объявления (в случае, если оно появилось)\n",
    "    #если объявление на сайте не появилось, то Selenium просто не найдет объект, отвечающий за него,\n",
    "    #и при попытке закрыть объявление сгенерируется исключение\n",
    "    #чтобы из-за этого исключения не падал весь дальнейший код, делаем обработку исключения с возможностью\n",
    "    #выполнения остатка кода\n",
    "    \n",
    "    try:\n",
    "        button_close = browser.find_element_by_class_name('b-promo_notification-popup-close')\n",
    "        button_close.click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    # Устанавливаем API ключ anti-captcha.com\n",
    "    # замените YOUR-ANTI-CAPTCHA-API-KEY на Ваш шестнадцатиричный ключ, который можно взять тут:\n",
    "    # https://anti-captcha.com/clients/settings/apisetup\n",
    "    \n",
    "    acp_api_send_request(\n",
    "        browser,\n",
    "        'setOptions',\n",
    "        {'options': {'antiCaptchaApiKey': anti_captcha_key}}\n",
    "    )\n",
    "\n",
    "    # Три секунды паузы чтобы плагин проверил ключ на стороне anti-captcha.com\n",
    "    time.sleep(10)\n",
    "    \n",
    "    return browser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Необходимо добавить функцию, которая будет колбасить курсором рандомно во избежание бана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_text_enter( element, text_input ):\n",
    "    time.sleep(random.uniform(2, 5)) \n",
    "    # sending_text = 'мошенничество'  text input \n",
    "    #document_text = browser.find_element_by_xpath('//textarea[@placeholder=\"текст документа\"]') \n",
    "    for letter in text_input: \n",
    "        time.sleep(random.uniform(0.05, 0.16)) \n",
    "        element.send_keys(letter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ф-ция, которая забивает форму на сайте нужными нам параметрами (пока параметры не все, потом добавим, сейчас в тестовом режиме)\n",
    "def get_page_by_input_attributes(browser= get_initial_page(  url = url, anti_captcha_key = anti_captcha_key  ), doc_text_in = '', date_from_in = '', date_to_in = '' ):\n",
    "    \n",
    "    document_text = browser.find_element_by_xpath('//textarea[@placeholder=\"текст документа\"]') #текст документа\n",
    "   # document_text.send_keys(doc_text_in)\n",
    "    \n",
    "    human_text_enter(document_text, doc_text_in) # Эмулируем ввод текста документа человеком\n",
    "    \n",
    "    #dispute_type = browser.find_element_by_xpath('//input[@placeholder=\"вид спора\"]') #вид спора\n",
    "    #dispute_category = browser.find_element_by_xpath('//input[@placeholder=\"категория спора\"]') #категория спора\n",
    "    \n",
    "    #case_participant = browser.find_element_by_xpath('//textarea[@placeholder=\"название, ИНН или ОГРН\"]') #название, ИНН или ОГРН\n",
    "    #court = browser.find_element_by_xpath('//input[@placeholder=\"название суда\"]') #название суда\n",
    "    #court.send_keys(court_in)\n",
    "    #case_number = browser.find_element_by_xpath('//input[@placeholder=\"например, А50-5568/08\"]') #номер дела\n",
    "    \n",
    "    date_from = browser.find_element_by_xpath('//label[@class=\"from\"]//input[@placeholder=\"дд.мм.гггг\"]') #нижняя граница даты\n",
    "    human_text_enter(date_from, date_from_in) # Эмулируем ввод дат человеком\n",
    "    \n",
    "    date_to = browser.find_element_by_xpath('//label[@class=\"to\"]//input[@placeholder=\"дд.мм.гггг\"]') #верхняя граница даты\n",
    "    human_text_enter(date_to, date_to_in)\n",
    "    \n",
    "    search_button = browser.find_element_by_xpath('//button[@alt=\"Найти\"]') #кнопка \"Найти\"\n",
    "    \n",
    "    # Самая важная чаcть: ждем не более 120 секунд пока индикатор антикаптчи с классом antigate_solver\n",
    "    # не получит класс solved, что означает что рекапча решена\n",
    "    WebDriverWait(browser, 120)\n",
    "    \n",
    "    # Отправляем форму\n",
    "    search_button.click()\n",
    "    \n",
    "    time.sleep(10)\n",
    "    #ищем ссылку для перехода на страницу документа и переходим по ней\n",
    "    return browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_parsing_page = get_page_by_input_attributes(doc_text_in =  doc_text_input ) # пока это текущий браузер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_links_from_1_page(fist_page=initial_parsing_page):\n",
    "    links = initial_parsing_page.find_elements_by_xpath(\"//a[@href]\")\n",
    "    all_links = list()\n",
    "    for link in links:\n",
    "        all_links.append(link.get_attribute(\"href\"))\n",
    "    return all_links\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_links(all_links): \n",
    "    pdf_links = list()\n",
    "    for link in all_links:\n",
    "        if '.pdf' in link:\n",
    "            pdf_links.append(link)\n",
    "        else:\n",
    "            continue\n",
    "    return pdf_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_found_documents(intial_page = initial_parsing_page):\n",
    "    total_count = initial_parsing_page.find_elements_by_xpath('//*[@id=\"contentHeader\"]/span[1]')\n",
    "    split_text = total_count[0].text.split()\n",
    "    return int(split_text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_doc_info_text(intial_page, n  ):\n",
    "    pattern_searh = '//*[@id=\"b-cases\"]/li['\n",
    "    pattern_searh = pattern_searh + str(n) + ']'\n",
    "    try:\n",
    "        current_page = initial_parsing_page.find_elements_by_xpath(pattern_searh) # будем итерироваться по индексу\n",
    "        description = current_page[0].text\n",
    "    except:\n",
    "        NoSuchElementException\n",
    "        pass\n",
    "    return description\n",
    "\n",
    "#можем выцепить порядковый номер дела, Номер дела, Инстанция, дата размещения документа , название документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем данные для заполнения бд \n",
    "def get_doc_attributes(description ):\n",
    "    ordinal_doc_number = int(description[0 : description.find('.') ]) # порядковый номер дела (нужен для показа загруженных материалов)\n",
    "    start_pos_case_number = description.find('\\n')\n",
    "    end_pos_case_number = description.find('\\n', start_pos_case_number + 1 ) # ищет второе вхождение этого символа в строке\n",
    "    case_number = description[start_pos_case_number + 1 : end_pos_case_number ] # Номер дела\n",
    "    try:\n",
    "        date_doc = re.findall(\"\\d{2}.\\d{2}.\\d{2,4}\", description)[1] # дата заливки документа\n",
    "    except:\n",
    "        IndexError # индекс не входит в диапазон элементов.\n",
    "        date_doc = re.findall(\"\\d{2}.\\d{2}.\\d{2,4}\", description)[0] # дата заливки документа\n",
    "    \n",
    "    court_name = description[end_pos_case_number + 1 : description.find(date_doc)] # Название суда, выносившего решение\n",
    "\n",
    "    start_doc_pos = description.find(date_doc) + 10\n",
    "    doc_name = description[ start_doc_pos : ]\n",
    "    indexs = [i for i, symb in enumerate(doc_name) if symb=='\\n']\n",
    "    document_name = '' # название документа\n",
    "    for i in range(len(doc_name)):\n",
    "        if i not in indexs:\n",
    "            document_name +=  doc_name[i] \n",
    "    \n",
    "    return ordinal_doc_number, case_number, date_doc, court_name, document_name\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачиваются все файлы с текущей страницы браузера. Доработать так, чтобы итерировалось еще по другим страницам\n",
    "def download_description(browser, pdf_links ):\n",
    "    \n",
    "    insert_values = { 'ordinal_number' : [], \n",
    "                      'case_number' : [],\n",
    "                      'date_doc' : [], \n",
    "                      'court_name' : [],\n",
    "                      'document_name' : [],\n",
    "                      'pdf_link' : [],\n",
    "                    }\n",
    "    \n",
    "    cnt_documents = count_found_documents() # Общее количество документов\n",
    "    \n",
    "    if cnt_documents > 40 * 25:\n",
    "        cnt_documents = 40 * 25 # Сайт выдает только 40 страниц по 25 документов \n",
    "    \n",
    "    for i in range(len(pdf_links)):\n",
    "        \n",
    "        description = current_doc_info_text(browser, i + 1 ) # получили описание нужного дока \n",
    "        \n",
    "        ordinal_doc_number, case_number, date_doc, court_name, document_name = get_doc_attributes(description = description)\n",
    "        \n",
    "        \n",
    "        # добавить в словарь key - value и расширять его по ключам \n",
    "        \n",
    "        \n",
    "      #  print(\"Идет загрузка документа {0} из {1}\".format(ordinal_doc_number, cnt_documents))\n",
    "        #print(ordinal_doc_number)\n",
    "        if pdf_links[i] not in insert_values['pdf_link']:\n",
    "            insert_values['ordinal_number'].append(ordinal_doc_number)\n",
    "            #print(case_number)\n",
    "            insert_values['case_number'].append(case_number)\n",
    "            #print(date_doc)\n",
    "            insert_values['date_doc'].append(date_doc)\n",
    "            #print(court_name)\n",
    "            insert_values['court_name'].append(court_name)\n",
    "            #print(document_name)\n",
    "            insert_values['document_name'].append(document_name)\n",
    "            #print(pdf_links[i]) # просто линк текущего документа\n",
    "            insert_values['pdf_link'].append(pdf_links[i])\n",
    "        #time.sleep(random.uniform(2, 3))  - раскомментить\n",
    "        else:\n",
    "            continue\n",
    "    return insert_values\n",
    "       \n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_documents(initial_parsing_page):\n",
    "    cnt_documents = count_found_documents(initial_parsing_page) # Общее количество документов\n",
    "    # Проход по всем страницам \n",
    "    flag = True\n",
    "    i = 1 # для теста нужно заменить, чтобы было не с 1 страницы \n",
    "    x_path = '//*[@id=\"pages\"]/li'\n",
    "    current_page = initial_parsing_page\n",
    "    links_need_to_be_downloaded = list()\n",
    "    list_of_insert_values = list()\n",
    "    while flag and i <= 12 : # убрать вторую часть условия для того, чтобы был парсинг ВСЕХ  страниц \n",
    "            #print(i)\n",
    "            if i < 10:\n",
    "                try :\n",
    "                    print(\"page nom \", i)\n",
    "                    next_page = initial_parsing_page.find_element_by_xpath( x_path + '[' + str(i + 2) + ']/a') # После парсинга текущей страницы переходим к следующей\n",
    "                    #print(x_path + '[' + str(i + 1) + ']/a')\n",
    "                   # print(\"ya tut 1 \")\n",
    "                    raw_links = get_row_links_from_1_page(fist_page=initial_parsing_page) # Получаем все \"сырые ссылки с текущей страницы\"\n",
    "                    #print(\"get_row_links_from_1_page = success\")\n",
    "                    pdf_links = get_pdf_links(raw_links) # Получаем ссылки на pdf-доки\n",
    "                    #print(\"get_pdf_links = success\")\n",
    "                    links_need_to_be_downloaded += pdf_links\n",
    "                    \n",
    "                    insert_values = download_description(initial_parsing_page, pdf_links)\n",
    "                    list_of_insert_values.append(insert_values)\n",
    "                    #download_docs(browser, pdf_links)\n",
    "                    \n",
    "                    next_next_page = next_page.click()\n",
    "                    #print(x_path + '[' + str(i + 1) + ']/a')\n",
    "                    i += 1 \n",
    "                    time.sleep(random.uniform(5, 10))         \n",
    "                except : \n",
    "                    NoSuchElementException\n",
    "                    flag = False  \n",
    "            \n",
    "           \n",
    "            elif i % 10 == 0:\n",
    "                try:\n",
    "                    if i == 10: \n",
    "                        j = 11\n",
    "                    else :\n",
    "                        j = 13 \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "\n",
    "                \n",
    "                    #print(x_path + '[' + str(i + 1) + ']/a' + 'elif')\n",
    "                    next_page = initial_parsing_page.find_element_by_xpath( x_path + '[' + str(j) + ']/a') # После парсинга текущей страницы переходим к следующей\n",
    "                \n",
    "                    \n",
    "                    raw_links = get_row_links_from_1_page(fist_page=initial_parsing_page) # Получаем все \"сырые ссылки с текущей страницы\"\n",
    "                    #print(\"get_row_links_from_1_page- succ\")\n",
    "                    pdf_links = get_pdf_links(raw_links) # Получаем ссылки на pdf-доки\n",
    "                    #print(\"get_pdf_links - succ \")\n",
    "                    links_need_to_be_downloaded += pdf_links\n",
    "                    \n",
    "                    insert_values = download_description(initial_parsing_page, pdf_links)\n",
    "                    #print(\"download_description - succ \")\n",
    "                    list_of_insert_values.append(insert_values) \n",
    "                    #print(\"append - succ \")\n",
    "                    \n",
    "                    #download_docs(browser, pdf_links)\n",
    "                    \n",
    "                    next_next_page = next_page.click()\n",
    "                    #print(x_path + '[' + str(j) + ']/a')\n",
    "                    i += 1 \n",
    "                    time.sleep(random.uniform(5, 10))          \n",
    "                    next_page = initial_parsing_page.find_element_by_xpath(x_path + '[' + str(j + 1 ) + ']/a') # После парсинга текущей страницы переходим к следующей\n",
    "                    next_page.click()\n",
    "                    time.sleep(random.uniform(5, 10))  \n",
    "\n",
    "                except:\n",
    "                    NoSuchElementException\n",
    "                    flag = False\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "            else:\n",
    "                try:\n",
    "                    next_page = initial_parsing_page.find_element_by_xpath( x_path + '[' + str(i % 10  + 3)  + ']/a') # После парсинга текущей страницы переходим к следующей\n",
    "                    #print(\"np=\", next_page)\n",
    "                    #print(\"ya tut \")\n",
    "                    raw_links = get_row_links_from_1_page(fist_page=initial_parsing_page) # Получаем все \"сырые ссылки с текущей страницы\"\n",
    "                    #print(\"get_row_links_from_1_page - else block  \")\n",
    "                    pdf_links = get_pdf_links(raw_links) # Получаем ссылки на pdf-доки\n",
    "                    #print(\"get_pdf_links - else block  \")\n",
    "                    links_need_to_be_downloaded += pdf_links\n",
    "                    \n",
    "                    insert_values = download_description(initial_parsing_page, pdf_links)\n",
    "                    #print(\"download_description - else block  \")\n",
    "                    \n",
    "                    # добавить проверку на то, что если есть такая ссылка, то не добавлять ее в список!\n",
    "                    \n",
    "                    \n",
    "                    list_of_insert_values.append(insert_values)\n",
    "                    #print(\"append - else block  \")\n",
    "                    #download_docs(browser, pdf_links)\n",
    "                    \n",
    "                    next_page.click()\n",
    "                    #print(\"click - else block  \")\n",
    "                    i += 1 \n",
    "                    time.sleep(random.uniform(5, 10))        \n",
    "                except : \n",
    "                    NoSuchElementException\n",
    "                    flag = False\n",
    "    # Если мы здесь - значит следующую страницу найти нельзя ( значит надо обработать текущую, т.е. последннюю )\n",
    "    raw_links = get_row_links_from_1_page(fist_page=initial_parsing_page) # Получаем все \"сырые ссылки с текущей страницы\"\n",
    "    pdf_links = get_pdf_links(raw_links) # Получаем ссылки на pdf-доки\n",
    "    links_need_to_be_downloaded += pdf_links       \n",
    "    insert_values = download_description(initial_parsing_page, pdf_links)\n",
    "    list_of_insert_values.append(insert_values)\n",
    "    initial_parsing_page.quit() \n",
    "                    \n",
    "                    \n",
    "          \n",
    "        \n",
    "    return links_need_to_be_downloaded, list_of_insert_values\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page nom  1\n",
      "page nom  2\n",
      "page nom  3\n",
      "page nom  4\n",
      "page nom  5\n",
      "page nom  6\n",
      "page nom  7\n",
      "page nom  8\n",
      "page nom  9\n"
     ]
    }
   ],
   "source": [
    "all_needed_links, list_of_insert_values = parse_all_documents(initial_parsing_page=initial_parsing_page)\n",
    "# Можно подавить вывод информации, которая появляется ниже, просто закомментив все print -ы, но для отладки так нагляднее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_insert_values = pd.concat([pd.DataFrame(d) for d in list_of_insert_values]).to_dict('list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "for i in res_insert_values['ordinal_number']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "325\n",
      "325\n",
      "325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(res_insert_values['ordinal_number']))\n",
    "print(len(res_insert_values['case_number']))\n",
    "print(len(res_insert_values['court_name']))\n",
    "print(len(res_insert_values['document_name']))\n",
    "\n",
    "check_list = list()\n",
    "for i in res_insert_values['ordinal_number']:\n",
    "    if i not in check_list:\n",
    "        check_list.append(i)\n",
    "    else:\n",
    "        continue\n",
    "len(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ordinal_number', 'case_number', 'date_doc', 'court_name', 'document_name', 'pdf_link'])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_insert_values.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделать проверку на уникальные ключи, чтобы дубли убрались"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_duplicates(res_insert_values):\n",
    "    \n",
    "    unique = list()\n",
    "    position = 0\n",
    "    \n",
    "    for i in res_insert_values['ordinal_number']:\n",
    "        if i not in unique and (len(unique) < (len(set(res_insert_values['ordinal_number'])))):\n",
    "            unique.append(i) #отбираем уникальные id-шники\n",
    "        else:\n",
    "            res_insert_values['ordinal_number'].pop(position)\n",
    "            res_insert_values['case_number'].pop(position)\n",
    "            res_insert_values['date_doc'].pop(position)\n",
    "            res_insert_values['court_name'].pop(position)\n",
    "            res_insert_values['document_name'].pop(position)\n",
    "            res_insert_values['pdf_link'].pop(position)\n",
    "        position += 1   \n",
    "            \n",
    "    df = pd.DataFrame.from_dict(res_insert_values)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = del_duplicates(res_insert_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ordinal_number</th>\n",
       "      <th>case_number</th>\n",
       "      <th>date_doc</th>\n",
       "      <th>court_name</th>\n",
       "      <th>document_name</th>\n",
       "      <th>pdf_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>А14-18572/2019</td>\n",
       "      <td>24.12.2020</td>\n",
       "      <td>АС Воронежской области</td>\n",
       "      <td>РЕШЕНИЕ СУДА ПЕРВОЙ ИНСТАНЦИИИСК УДОВЛЕТВОРИТЬ...</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/56716b9d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>А19-4481/2019</td>\n",
       "      <td>21.04.2020</td>\n",
       "      <td>АС Иркутской области</td>\n",
       "      <td>ОБ ОТЛОЖЕНИИ РАССМОТРЕНИЯ ЗАЯВЛЕНИЯ/ЖАЛОБЫ</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/c8e42cde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>А60-5329/2020</td>\n",
       "      <td>21.04.2020</td>\n",
       "      <td>АС Свердловской области</td>\n",
       "      <td>[ПОДПИСАНО]РЕЗОЛЮТИВНАЯ ЧАСТЬ РЕШЕНИЯ СУДА ПО ...</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/93a07648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>А72-2592/2020</td>\n",
       "      <td>21.04.2020</td>\n",
       "      <td>АС Ульяновской области</td>\n",
       "      <td>РЕЗОЛЮТИВНАЯ ЧАСТЬ РЕШЕНИЯ СУДА ПО ДЕЛУ, РАССМ...</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/4e77f77c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>А42-11728/2019</td>\n",
       "      <td>21.04.2020</td>\n",
       "      <td>АС Мурманской области</td>\n",
       "      <td>О ВКЛЮЧЕНИИ ТРЕБОВАНИЙ В РЕЕСТР ТРЕБОВАНИЙ КРЕ...</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/ad60efea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>296</td>\n",
       "      <td>А60-66730/2019</td>\n",
       "      <td>17.04.2020</td>\n",
       "      <td>17 арбитражный апелляционный суд</td>\n",
       "      <td>ПОСТАНОВЛЕНИЕ СУДА АПЕЛЛЯЦИОННОЙ ИНСТАНЦИИОСТА...</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/f426d7e5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>297</td>\n",
       "      <td>А72-682/2020</td>\n",
       "      <td>17.04.2020</td>\n",
       "      <td>АС Ульяновской области</td>\n",
       "      <td>МОТИВИРОВАННОЕ РЕШЕНИЕ ПО ДЕЛУ, РАССМОТРЕННОМУ...</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/c2cbe5e3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>А03-3829/2020</td>\n",
       "      <td>17.04.2020</td>\n",
       "      <td>АС Алтайского края</td>\n",
       "      <td>О ВОЗВРАЩЕНИИ ИСКОВОГО ЗАЯВЛЕНИЯ (ЗАЯВЛЕНИЯ)</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/ad7dbf55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>А76-13141/2020</td>\n",
       "      <td>17.04.2020</td>\n",
       "      <td>АС Челябинской области</td>\n",
       "      <td>СУДЕБНЫЙ ПРИКАЗИСК УДОВЛЕТВОРИТЬ ПОЛНОСТЬЮ</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/06d52d84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>А65-7132/2020</td>\n",
       "      <td>17.04.2020</td>\n",
       "      <td>АС Республики Татарстан</td>\n",
       "      <td>[ПОДПИСАНО]ПРЕКРАТИТЬ ПРОИЗВОДСТВО ПО ДЕЛУ, ПР...</td>\n",
       "      <td>https://ras.arbitr.ru/Kad/PdfDocument/8db88fba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ordinal_number     case_number    date_doc  \\\n",
       "0                 1  А14-18572/2019  24.12.2020   \n",
       "1                 2   А19-4481/2019  21.04.2020   \n",
       "2                 3   А60-5329/2020  21.04.2020   \n",
       "3                 4   А72-2592/2020  21.04.2020   \n",
       "4                 5  А42-11728/2019  21.04.2020   \n",
       "..              ...             ...         ...   \n",
       "295             296  А60-66730/2019  17.04.2020   \n",
       "296             297    А72-682/2020  17.04.2020   \n",
       "297             298   А03-3829/2020  17.04.2020   \n",
       "298             299  А76-13141/2020  17.04.2020   \n",
       "299             300   А65-7132/2020  17.04.2020   \n",
       "\n",
       "                            court_name  \\\n",
       "0              АС Воронежской области    \n",
       "1                АС Иркутской области    \n",
       "2             АС Свердловской области    \n",
       "3              АС Ульяновской области    \n",
       "4               АС Мурманской области    \n",
       "..                                 ...   \n",
       "295  17 арбитражный апелляционный суд    \n",
       "296            АС Ульяновской области    \n",
       "297                АС Алтайского края    \n",
       "298            АС Челябинской области    \n",
       "299           АС Республики Татарстан    \n",
       "\n",
       "                                         document_name  \\\n",
       "0    РЕШЕНИЕ СУДА ПЕРВОЙ ИНСТАНЦИИИСК УДОВЛЕТВОРИТЬ...   \n",
       "1           ОБ ОТЛОЖЕНИИ РАССМОТРЕНИЯ ЗАЯВЛЕНИЯ/ЖАЛОБЫ   \n",
       "2    [ПОДПИСАНО]РЕЗОЛЮТИВНАЯ ЧАСТЬ РЕШЕНИЯ СУДА ПО ...   \n",
       "3    РЕЗОЛЮТИВНАЯ ЧАСТЬ РЕШЕНИЯ СУДА ПО ДЕЛУ, РАССМ...   \n",
       "4    О ВКЛЮЧЕНИИ ТРЕБОВАНИЙ В РЕЕСТР ТРЕБОВАНИЙ КРЕ...   \n",
       "..                                                 ...   \n",
       "295  ПОСТАНОВЛЕНИЕ СУДА АПЕЛЛЯЦИОННОЙ ИНСТАНЦИИОСТА...   \n",
       "296  МОТИВИРОВАННОЕ РЕШЕНИЕ ПО ДЕЛУ, РАССМОТРЕННОМУ...   \n",
       "297       О ВОЗВРАЩЕНИИ ИСКОВОГО ЗАЯВЛЕНИЯ (ЗАЯВЛЕНИЯ)   \n",
       "298         СУДЕБНЫЙ ПРИКАЗИСК УДОВЛЕТВОРИТЬ ПОЛНОСТЬЮ   \n",
       "299  [ПОДПИСАНО]ПРЕКРАТИТЬ ПРОИЗВОДСТВО ПО ДЕЛУ, ПР...   \n",
       "\n",
       "                                              pdf_link  \n",
       "0    https://ras.arbitr.ru/Kad/PdfDocument/56716b9d...  \n",
       "1    https://ras.arbitr.ru/Kad/PdfDocument/c8e42cde...  \n",
       "2    https://ras.arbitr.ru/Kad/PdfDocument/93a07648...  \n",
       "3    https://ras.arbitr.ru/Kad/PdfDocument/4e77f77c...  \n",
       "4    https://ras.arbitr.ru/Kad/PdfDocument/ad60efea...  \n",
       "..                                                 ...  \n",
       "295  https://ras.arbitr.ru/Kad/PdfDocument/f426d7e5...  \n",
       "296  https://ras.arbitr.ru/Kad/PdfDocument/c2cbe5e3...  \n",
       "297  https://ras.arbitr.ru/Kad/PdfDocument/ad7dbf55...  \n",
       "298  https://ras.arbitr.ru/Kad/PdfDocument/06d52d84...  \n",
       "299  https://ras.arbitr.ru/Kad/PdfDocument/8db88fba...  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['ordinal_number']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "for i in df['ordinal_number']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание схемы бд  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_db = 'my_vkr.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_connection(db_name = name_db):\n",
    "    try:\n",
    "        con = sqlite3.connect(name_db) # устанавливаем соединение с БД\n",
    "        return con\n",
    "    except Error:\n",
    "        print(Error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sql_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables(connection = con):\n",
    "    cursor_obj = con.cursor()\n",
    "    cursor_obj.execute(\"\"\" CREATE TABLE SEARCH_PARAMS(\n",
    "                           ID_DOC INTEGER,  \n",
    "                           SEARCH_DIRECTION TEXT,\n",
    "                           DATE_FROM TEXT, \n",
    "                           DATE_TO TEXT,\n",
    "                           DOWNLOAD_DATE TEXT,\n",
    "                           LOCATED_IN_DIRECTORY TEXT ) \"\"\")\n",
    "    con.commit()\n",
    "    \n",
    "    cursor_obj = con.cursor()\n",
    "    cursor_obj.execute(\"\"\" CREATE TABLE DOC_INFO(\n",
    "                           ID_DOC INTEGER, \n",
    "                           CASE_NUMBER TEXT, \n",
    "                           DATE_ON_SITE TEXT, -- LAST DATE OF UPDATING DOCUMENT ON SITE \n",
    "                           COURT_NAME TEXT, \n",
    "                           DOC_TITLE TEXT, \n",
    "                           PDF_LINK TEXT) \"\"\")\n",
    "    con.commit()\n",
    "    \n",
    "    \n",
    "    # ЗДЕСЬ ЕЩЕ ДОЛЖНЫ ПОЯВИТЬСЯ 2 СУЩНОСТИ - ТАБЛИЦА С РЕЙТИНГАМИ ДОКОВ ( ПОСЛЕ ТОГО, КАК ОПРЕДЕЛИМСЯ, КАК ОЦЕНИВАЕМ)\n",
    "    # И ТАБЛИЦА С ЮЗЕРАМИ, КОТОРЫЕ БУДУТ ИМЕТЬ ДОСТУП К БД ИЛИ ТИП ТОГО\n",
    "    # надо обсудить этот момент\n",
    "    \n",
    "    con.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    create_tables(connection = con) # создание табличек выдает ошибку если таблички уже существуют \n",
    "except:\n",
    "    print(\"Table already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_constraints_on_tables(connection  = con):  # пока прототип будущей функции. Нужно согласовать, что будет PK \n",
    "    cursor_obj = con.cursor()\n",
    "    cursor_obj.execute(\"\"\" ALTER TABLE SEARCH_PARAMS ADD CONSTRAINT ..... \"\"\") \n",
    "    \n",
    "    con.commit()\n",
    "    \n",
    "    cursor_obj.execute(\"\"\" ALTER TABLE DOC_INFO ADD CONSTRAINT .... \"\"\")\n",
    "    \n",
    "    con.commit()\n",
    "    \n",
    "    con.close()\n",
    "    \n",
    "    # первичные ключи определить и еще мб какую-н сущность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нужен автоинкремент, чтобы при добавлении в таблицу взять след значение как первичный ключ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_docs( browser, df,  connection = con):\n",
    "    cursor_obj = con.cursor()\n",
    "    #browser = get_initial_page()\n",
    "    n = len(df['ordinal_number'])\n",
    "    for i in range(len(df['ordinal_number'])):\n",
    "        print(\"Загрузка документа {0} из {1}\".format(i + 1, n ))\n",
    "        browser.get(df['pdf_link'][i]) # скачиваем документ по ссылке \n",
    "        \n",
    "        cursor_obj.execute(\"\"\"\n",
    "        INSERT INTO DOC_INFO(\n",
    "                    ID_DOC, \n",
    "                    CASE_NUMBER, \n",
    "                    DATE_ON_SITE, -- LAST DATE OF UPDATING DOCUMENT ON SITE \n",
    "                    COURT_NAME, \n",
    "                    DOC_TITLE, \n",
    "                    PDF_LINK)  \n",
    "        VALUES (?, ?, ?, ?, ?, ?)\"\"\", \n",
    "                ( df['ordinal_number'][i],\n",
    "                  df['case_number'][i],\n",
    "                  df['date_doc'][i],\n",
    "                  df['court_name'][i],\n",
    "                  df['document_name'][i],\n",
    "                  df['pdf_link'][i]) )\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        now = datetime.datetime.now()\n",
    "        \n",
    "        cursor_obj.execute(\"\"\"\n",
    "        INSERT INTO SEARCH_PARAMS(\n",
    "                    ID_DOC,\n",
    "                    SEARCH_DIRECTION, \n",
    "                    DATE_FROM, \n",
    "                    DATE_TO,  \n",
    "                    DOWNLOAD_DATE, \n",
    "                    LOCATED_IN_DIRECTORY)\n",
    "                    \n",
    "        VALUES (?, ?, ?, ?, ?, ?)\"\"\", \n",
    "                ( df['ordinal_number'][i],\n",
    "                  doc_text_input,\n",
    "                  date_from,\n",
    "                  date_to,\n",
    "                  now.strftime(\"%d-%m-%Y %H:%M\"),\n",
    "                  download_directory) )\n",
    "        \n",
    "        \n",
    "        time.sleep(random.uniform(5, 10))\n",
    "        \n",
    "        con.commit()\n",
    "        \n",
    "    browser.quit()\n",
    "        \n",
    "        # Заполнять еще таблицы, о которых упомяналось выше ( с рейтингами доков и юзерами ) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "browser = webdriver.Chrome(path_to_user_driver, options=init_chrome_options(path_to_anticaptcha_plugin) )\n",
    "\n",
    "download_docs( browser =  browser , df = df ,  connection = con  ) # загрузка доков в указанную папку\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
